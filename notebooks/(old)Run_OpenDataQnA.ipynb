{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"display: flex; align-items: left;\">\n",
        "    <a href=\"https://sites.google.com/corp/google.com/genai-solutions/home?authuser=0\">\n",
        "        <img src=\"https://storage.googleapis.com/miscfilespublic/Linkedin%20Banner%20%E2%80%93%202.png\" style=\"margin-right\">\n",
        "    </a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "copyright"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRyGcAepAPJ5"
      },
      "source": [
        "\n",
        "<h1 align=\"center\">Open Data QnA - Chat with your SQL Database</h1> \n",
        "\n",
        "---\n",
        "\n",
        "This notebook first walks through the Vector Store Setup needed for running the Open Data QnA application. \n",
        "\n",
        "Currently supported Source DBs are: \n",
        "- PostgreSQL on Google Cloud SQL \n",
        "- BigQuery\n",
        "\n",
        "Furthermore, the following vector stores are supported \n",
        "- pgvector on PostgreSQL \n",
        "- BigQuery vector\n",
        "\n",
        "\n",
        "The setup part covers the following steps: \n",
        "> 1. Configuration: Intial GCP project, IAM permissions, Environment  and Databases setup including logging on Bigquery for analytics\n",
        "\n",
        "> 2. Creation of Table, Column and Known Good Query Embeddings in the Vector Store  for Retreival Augmented Generation(RAG)\n",
        "\n",
        "\n",
        "Afterwards, you will be able to run the Open Data QnA Pipeline to generate SQL queries and answer questions over your data source. \n",
        "\n",
        "The pipeline run covers the following steps: \n",
        "\n",
        "> 1. Take user question and generate sql in the dialect corresponding to data source\n",
        "\n",
        "> 2. Execute the sql query and retreive the data\n",
        "\n",
        "> 3. Generate natural language respose and charts to display\n",
        "\n",
        "> 4. Clean Up resources\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsWGZW_fUJjN"
      },
      "source": [
        "### üìí Using this interactive notebook\n",
        "\n",
        "If you have not used this IDE with jupyter notebooks it will ask for installing Python + Jupyter extensions. Please go ahead install them\n",
        "\n",
        "Click the **run** icons ‚ñ∂Ô∏è  of each cell within this notebook.\n",
        "\n",
        "> üí° Alternatively, you can run the currently selected cell with `Ctrl + Enter` (or `‚åò + Enter` on a Mac).\n",
        "\n",
        "> ‚ö†Ô∏è **To avoid any errors**, wait for each section to finish in their order before clicking the next ‚Äúrun‚Äù icon.\n",
        "\n",
        "This sample must be connected to a **Google Cloud project**, but nothing else is needed other than your Google Cloud project.\n",
        "\n",
        "You can use an existing project. Alternatively, you can create a new Cloud project [with cloud credits for free.](https://cloud.google.com/free/docs/gcp-free-tier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RicDCkdI-hmp"
      },
      "source": [
        "# üöß **0. Prerequisites**\n",
        "\n",
        "Make sure that Google Cloud CLI is installed before moving to the next cell! You can refer to the link below for guidance\n",
        "\n",
        "Installation Guide: https://cloud.google.com/sdk/docs/install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  **0.1. Setup Poetry Environment and Setup GCP Project** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üíª **Install Code Dependencies (Create and setup venv)**\n",
        "Install the dependencies by runnign the poetry commands below \n",
        "\n",
        "Note: Below command runs with default Python Kernel and we will change that to Kernel from venv after this execution below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install poetry\n",
        "! pip uninstall poetry -y\n",
        "! pip install poetry --quiet\n",
        "\n",
        "#Run the poetry commands below to set up the environment\n",
        "!poetry lock #resolve dependecies (also auto create poetry venv if not exists)\n",
        "!poetry install --quiet #installs dependencies\n",
        "!poetry env info #Displays the evn just created and the path to it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìå **Important Step: Activate your virtual environment [Run all these on Terminal]**\n",
        "\n",
        "Once the venv created either in the local directory or in the cache directory. Open the terminal on the same machine where your notebooks are running and start running the below commands.\n",
        "\n",
        "\n",
        "```\n",
        "poetry shell #this command should activate your venv and you should see it enters into the venv\n",
        "\n",
        "##inside the activated venv shell\n",
        "\n",
        "gcloud auth login\n",
        "gcloud auth application-default login\n",
        "gcloud services enable \\\n",
        "    serviceusage.googleapis.com \\\n",
        "    cloudresourcemanager.googleapis.com --project <<Enter Project Id>>\n",
        "gcloud auth application-default set-quota-project <<Enter Project Id for using resources>>\n",
        "\n",
        "```\n",
        "For IDEs adding Juypter Extensions will automatically give you option to change the kernel. If not, manually select the python interpreter in your IDE (The exact is shown in the above cell. Path would look like e.g. /home/admin_/Talk2Data/.venv/bin/python or ~cache/user/Talk2Data/.venv/bin/python)\n",
        "\n",
        "**Extra Steps if you are running inside Jupyter Lab or Jupyter Environments on Workbench etc**\n",
        "\n",
        "We need to manually add venv as Kernel in the those instance where you don't have choice to select the path manually like above.\n",
        "\n",
        "Run the steps above and continue with below\n",
        "\n",
        "```\n",
        "##still inside the activated venv shell\n",
        "\n",
        "pip install jupyter\n",
        "\n",
        "ipython kernel install --name \"openqna-venv\" --user \n",
        "\n",
        "```\n",
        "\n",
        "Restart your kernel or close the exsiting notebook and open again, you should now see the \"openqna-venv\" in the kernel drop down\n",
        "\n",
        "**What did we do here?**\n",
        "\n",
        "* Created Application Default Credentials to use for the code\n",
        "* Added venv to kernel to select for runningt the notebooks (For standalone Jupyter setups like Workbench etc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4W6FPnrYEE8"
      },
      "source": [
        "### üîó **Connect Your Google Cloud Project**\n",
        "Time to connect your Google Cloud Project to this notebook. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@markdown Please fill in the value below with your GCP project ID and then run the cell.\n",
        "PROJECT_ID = \"my_project\"\n",
        "\n",
        "# Quick input validations.\n",
        "assert PROJECT_ID, \"‚ö†Ô∏è Please provide your Google Cloud Project ID\"\n",
        "\n",
        "# Configure gcloud.\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "print(f'Project has been set to {PROJECT_ID}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yygMe6rPWxHS"
      },
      "source": [
        "### üîê **Authenticate to Google Cloud**\n",
        "Authenticate to Google Cloud as the IAM user logged into this notebook in order to access your Google Cloud Project.\n",
        "You can do this within Google Colab or using the Application Default Credentials in the Google Cloud CLI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Colab Auth\"\"\" \n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "\n",
        "import google.auth\n",
        "import os\n",
        "\n",
        "credentials, project_id = google.auth.default()\n",
        "\n",
        "os.environ['GOOGLE_CLOUD_QUOTA_PROJECT']=PROJECT_ID\n",
        "os.environ['GOOGLE_CLOUD_PROJECT']=PROJECT_ID\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚öôÔ∏è **Enable Required API Services in the GCP Project**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Enable all the required APIs for the Open Data QnA solution\n",
        "\n",
        "!gcloud services enable \\\n",
        "  cloudapis.googleapis.com \\\n",
        "  iam.googleapis.com \\\n",
        "  run.googleapis.com \\\n",
        "  sqladmin.googleapis.com \\\n",
        "  aiplatform.googleapis.com \\\n",
        "  bigquery.googleapis.com \\\n",
        "  storage.googleapis.com \\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **1. Vector Store Setup** (Run once)\n",
        "---\n",
        "\n",
        "This section walks through the Vector Store Setup needed for running the Open Data QnA application. \n",
        "\n",
        "It covers the following steps: \n",
        "> 1. Configuration: Environment and Databases setup including logging on Bigquery for analytics\n",
        "\n",
        "> 2. Creation of Table, Column and Known Good Query Embeddings in the Vector Store  for Retreival Augmented Generation(RAG)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà **1.1 Set Up your Data Source and Vector Store**\n",
        "\n",
        "This section assumes that a datasource is already set up in your GCP project. If a datasource has not been set up, use the notebooks below to copy a public data set from BigQuery to Cloud SQL or BigQeury on your GCP project\n",
        "\n",
        "\n",
        "Enabled Data Sources:\n",
        "* PostgreSQL on Google Cloud SQL (Copy Sample Data: [0_CopyDataToCloudSqlPG.ipynb](0_CopyDataToCloudSqlPG.ipynb))\n",
        "* BigQuery (Copy Sample Data: [0_CopyDataToBigQuery.ipynb](0_CopyDataToBigQuery.ipynb))\n",
        "\n",
        "Enabled Vector Stores:\n",
        "* pgvector on PostgreSQL \n",
        "* BigQuery vector\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ü§î **Choose Data Source and Vector Store**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fill out the parameters and configuration settings below. \n",
        "These are the parameters for connecting to the source databases and setting configurations for the vector store tables to be created. \n",
        "Additionally, you can specify whether you have and want to use known-good-queries for the pipeline run and whether you want to enable logging.\n",
        "\n",
        "**Known good queries:** if you have known working user question <-> SQL query pairs, you can put them into the file `scripts/known_good_sql.csv`. This will be used as a caching layer and for in-context learning: If an exact match of the user question is found in the vector store, the pipeline will skip SQL Generation and output the cached SQL query. If the similarity score is between 90-100%, the known good queries will be used as few-shot examples by the SQL Generator Agent. \n",
        "\n",
        "**Logging:** you can enable logging. If enabled, a dataset is created in Big Query in your project, which will store the logging table and save information from the pipeline run in the logging table. This is especially helpful for debugging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data source details\n",
        "DATA_SOURCE = 'bigquery' # Options: 'bigquery' and 'cloudsql-pg' i.e, PostgreSQL database on Google Cloud SQL\n",
        "\n",
        "# Please specify what you would like to use as vector store for embeddings\n",
        "VECTOR_STORE = 'bigquery-vector' # Options: 'bigquery-vector' i.e, Bigquery vector and 'cloudsql-pgvector' i.e, pgvector on PostgreSQL\n",
        "\n",
        "\n",
        "# If you have chosen 'cloudsql-pg' as DATA_SOURCE; provide information below\n",
        "PG_REGION = \"\" #@param {type:\"string\"}\n",
        "PG_INSTANCE = \"\"\n",
        "PG_DATABASE = \"\"\n",
        "PG_USER = \"\"\n",
        "PG_PASSWORD = \"\"\n",
        "PG_SCHEMA = '' # Name of the dataset that contains all the tables\n",
        "\n",
        "\n",
        "# If you have chosen 'bigquery' as DATA_SOURCE; provide information below\n",
        "BQ_REGION = 'us-central1'\n",
        "BQ_DATASET_NAME = 'imdb'\n",
        "# you can specify the names of the bq tables you want to query over specifially. If left empty, Open Data QnA will parse through all the tables in the dataset.\n",
        "BQ_TABLE_LIST = None # either None or a list of table names in format ['reviews', 'ratings']\n",
        "\n",
        "\n",
        "# Specify if you have example question & known-good-query pairs you want to leverage \n",
        "EXAMPLES = False \n",
        "\n",
        "# Please specify if you want to enable Logging. Logging will create a BQ table and store logs of the Open Data QnA Pipeline run. \n",
        "LOGGING = True \n",
        "\n",
        "# If Logging is enabled, specify the name for the log table. You call leave it at the default value. \n",
        "BQ_LOG_TABLE_NAME = 'audit_log_table' \n",
        "\n",
        "# If Logging is enabled OR you are using bigquery-vector as the data store, a Big Query dataset will be created to hold the tables. \n",
        "# You can rename the table below if you wish to do so. \n",
        "BQ_OPENDATAQNA_DATASET_NAME = 'opendataqna'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quick input verifications below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Input verification - Source\n",
        "assert DATA_SOURCE in {'bigquery', 'cloudsql-pg'}, \"‚ö†Ô∏è Invalid DATA_SOURCE. Must be 'bigquery' or 'cloudsql-pg'\"\n",
        "\n",
        "# Input verification - Vector Store\n",
        "assert VECTOR_STORE in {'bigquery-vector', 'cloudsql-pgvector'}, \"‚ö†Ô∏è Invalid VECTOR_STORE. Must be 'bigquery-vector' or 'cloudsql-pgvector'\"\n",
        "\n",
        "if LOGGING: \n",
        "    assert BQ_LOG_TABLE_NAME, \"‚ö†Ô∏è Please provide a name for your log table if you want to use logging\"\n",
        "\n",
        "if DATA_SOURCE == 'bigquery':\n",
        "    assert BQ_REGION, \"‚ö†Ô∏è Please provide the Data Set Region\"\n",
        "    assert BQ_DATASET_NAME, \"‚ö†Ô∏è Please provide the name of the dataset on Bigquery\"\n",
        "\n",
        "    DATASET_REGION = BQ_REGION\n",
        "\n",
        "elif DATA_SOURCE == 'cloudsql-pg':\n",
        "    assert PG_REGION, \"‚ö†Ô∏è Please provide Region of the Cloud SQL Instance\"\n",
        "    assert PG_INSTANCE, \"‚ö†Ô∏è Please provide the name of the Cloud SQL Instance\"\n",
        "    assert PG_DATABASE, \"‚ö†Ô∏è Please provide the name of the PostgreSQL Database on the Cloud SQL Instance\"\n",
        "    assert PG_USER, \"‚ö†Ô∏è Please provide a username for the Cloud SQL Instance\"\n",
        "    assert PG_PASSWORD, \"‚ö†Ô∏è Please provide the Password for the PG_USER\"\n",
        "\n",
        "    DATASET_REGION = PG_REGION\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üíæ **Save Configuration to File** \n",
        "Save the configurations set in this notebook to  `config.ini`. The parameters from this file are used in notebooks and in various modeules in the repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All configuration paramaters saved to file!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import configparser\n",
        "\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "sys.path.append(module_path)\n",
        "\n",
        "config = configparser.ConfigParser()\n",
        "config.read(module_path+'/config.ini')\n",
        "\n",
        "config['GCP']['PROJECT_ID'] = PROJECT_ID\n",
        "config['CONFIG']['DATA_SOURCE'] = DATA_SOURCE\n",
        "config['CONFIG']['VECTOR_STORE'] = VECTOR_STORE\n",
        "\n",
        "# Save the parameters based on Data Source and Vector Store Choices\n",
        "if DATA_SOURCE == 'cloudsql-pg' or VECTOR_STORE == 'cloudsql-pgvector':\n",
        "    config['PGCLOUDSQL']['PG_INSTANCE'] = PG_INSTANCE\n",
        "    config['PGCLOUDSQL']['PG_DATABASE'] = PG_DATABASE\n",
        "    config['PGCLOUDSQL']['PG_USER'] = PG_USER\n",
        "    config['PGCLOUDSQL']['PG_PASSWORD'] = PG_PASSWORD\n",
        "    config['PGCLOUDSQL']['PG_REGION'] = PG_REGION\n",
        "    config['PGCLOUDSQL']['PG_SCHEMA'] = PG_SCHEMA\n",
        "\n",
        "if DATA_SOURCE := 'bigquery':\n",
        "    config['BIGQUERY']['BQ_DATASET_REGION'] = BQ_REGION\n",
        "    config['BIGQUERY']['BQ_DATASET_NAME'] = BQ_DATASET_NAME\n",
        "    config['BIGQUERY']['BQ_OPENDATAQNA_DATASET_NAME'] = BQ_OPENDATAQNA_DATASET_NAME\n",
        "    config['BIGQUERY']['BQ_TABLE_LIST'] = str(BQ_TABLE_LIST)\n",
        "    config['BIGQUERY']['BQ_LOG_TABLE_NAME'] = BQ_LOG_TABLE_NAME\n",
        "\n",
        "if LOGGING: \n",
        "    config['BIGQUERY']['LOGGING'] = 'yes'\n",
        "    config['BIGQUERY']['BQ_LOG_TABLE_NAME'] = BQ_LOG_TABLE_NAME\n",
        "\n",
        "else: \n",
        "    config['BIGQUERY']['LOGGING'] = 'no'\n",
        "\n",
        "\n",
        "with open(module_path+'/config.ini', 'w') as configfile:    # save\n",
        "    config.write(configfile)\n",
        "\n",
        "print('All configuration paramaters saved to file!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚öôÔ∏è **Database Setup for Vector Store: CloudSQL-pgvector**\n",
        "\n",
        "Create PostgreSQL Instance on CloudSQL if 'cloudsql-pgvector' is chosen as vector store\n",
        "\n",
        "Note that a PostgreSQL Instance on CloudSQL already exists if 'cloudsql-pg' is the data source. PostgreSQL Instance is created only if a different data store is chosen.\n",
        "\n",
        "The cell will also create a dataset to store the log table on Big Query, **if** logging is enabled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Destination Dataset exists\n"
          ]
        }
      ],
      "source": [
        "#@markdown Feel free to update PostgreSQL or BigQuery parameters.\n",
        "# If not updated, we will proceed with default values!\n",
        "\n",
        "# Create PostgreSQL Instance is data source is different from PostgreSQL Instance\n",
        "if VECTOR_STORE == 'cloudsql-pgvector' and DATA_SOURCE != 'cloudsql-pg':\n",
        "  # Parameters for PostgreSQL Instance\n",
        "  PG_REGION = DATASET_REGION\n",
        "  PG_INSTANCE = \"pg15-opendataqna\"\n",
        "  PG_DATABASE = \"opendataqna-db\"\n",
        "  PG_USER = \"pguser\"\n",
        "  PG_PASSWORD = \"pg123\"\n",
        "  PG_SCHEMA = 'pg-vector-store' \n",
        "\n",
        "\n",
        "  # check if Cloud SQL instance exists in the provided region\n",
        "  database_version = !gcloud sql instances describe {PG_INSTANCE} --format=\"value(databaseVersion)\"\n",
        "  if database_version[0].startswith(\"POSTGRES\"):\n",
        "    print(\"Found existing Postgres Cloud SQL Instance!\")\n",
        "  else:\n",
        "    print(\"Creating new Cloud SQL instance...\")\n",
        "    !gcloud sql instances create {PG_INSTANCE} --database-version=POSTGRES_15 \\\n",
        "      --region={PG_REGION} --cpu=1 --memory=4GB --root-password={PG_PASSWORD} \\\n",
        "      --database-flags=cloudsql.iam_authentication=On\n",
        "\n",
        "  # Create a database on the instance and a user with password\n",
        "  database_exists = !gcloud sql databases list --instance={PG_INSTANCE} | grep -z 'NAME: {PG_DATABASE}'\n",
        "  if database_exists:\n",
        "      print(\"Found existing Postgres Cloud SQL database!\")\n",
        "  else:\n",
        "      print(\"Creating new Cloud SQL database...\")\n",
        "      !gcloud sql databases create  {PG_DATABASE} --instance={PG_INSTANCE}\n",
        "  !gcloud sql users create {PG_USER} \\\n",
        "  --instance={PG_INSTANCE} \\\n",
        "  --password={PG_PASSWORD}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create a new data set on Bigquery to use for the logs table\n",
        "if LOGGING:\n",
        "  BQ_OPENDATAQNA_DATASET_NAME = \"opendataqna\" #@param {type:\"string\"} - name of the dataset in Vector Store\n",
        "\n",
        "  from google.cloud import bigquery\n",
        "  import google.api_core \n",
        "  client=bigquery.Client(project=PROJECT_ID)\n",
        "  dataset_ref = f\"{PROJECT_ID}.{BQ_OPENDATAQNA_DATASET_NAME}\"\n",
        "\n",
        "\n",
        "  # Create the dataset if it does not exist already\n",
        "  try:\n",
        "      client.get_dataset(dataset_ref)\n",
        "      print(\"Destination Dataset exists\")\n",
        "  except google.api_core.exceptions.NotFound:\n",
        "      print(\"Cannot find the dataset hence creating.......\")\n",
        "      dataset=bigquery.Dataset(dataset_ref)\n",
        "      dataset.location=DATASET_REGION\n",
        "      client.create_dataset(dataset)\n",
        "      print(str(dataset_ref)+\" is created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚öôÔ∏è  **Database Setup for Vector Store: BigQuery-vector**\n",
        "\n",
        "Create dataset on Big Query to store the embeddings tables.\n",
        "If Bigquery is the vector store, the same database is used for logging. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Destination Dataset exists\n"
          ]
        }
      ],
      "source": [
        "# Create a new data set on Bigquery to use as Vector store; the same will be used for logging as well\n",
        "if VECTOR_STORE == 'bigquery-vector':\n",
        "  BQ_OPENDATAQNA_DATASET_NAME = \"opendataqna\" #@param {type:\"string\"} - name of the dataset in Vector Store\n",
        "\n",
        "  from google.cloud import bigquery\n",
        "  import google.api_core \n",
        "  client=bigquery.Client(project=PROJECT_ID)\n",
        "  dataset_ref = f\"{PROJECT_ID}.{BQ_OPENDATAQNA_DATASET_NAME}\"\n",
        "\n",
        "\n",
        "  # Create the dataset if it does not exist already\n",
        "  try:\n",
        "      client.get_dataset(dataset_ref)\n",
        "      print(\"Destination Dataset exists\")\n",
        "  except google.api_core.exceptions.NotFound:\n",
        "      print(\"Cannot find the dataset hence creating.......\")\n",
        "      dataset=bigquery.Dataset(dataset_ref)\n",
        "      dataset.location=DATASET_REGION\n",
        "      client.create_dataset(dataset)\n",
        "      print(str(dataset_ref)+\" is created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  **1.2. Create Embeddings in Vector Store for RAG** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üñãÔ∏è **Create Table and Column Embeddings**\n",
        "\n",
        "In this step, table and column metadata is retreived from the data source and embeddings are generated for both"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source Selected is bigquery\n",
            "\n",
            "LLM generated 8 Table Descriptions\n",
            "\n",
            "LLM generated 0 Column Descriptions\n",
            "Table and Column embeddings are created\n"
          ]
        }
      ],
      "source": [
        "# Create Table and Column Embeddings\n",
        "from embeddings.retrieve_embeddings import retrieve_embeddings\n",
        "\n",
        "if DATA_SOURCE =='bigquery':\n",
        "    table_schema_embeddings, col_schema_embeddings = retrieve_embeddings(DATA_SOURCE, SCHEMA=BQ_DATASET_NAME, table_names=BQ_TABLE_LIST)\n",
        "else: \n",
        "    table_schema_embeddings, col_schema_embeddings = retrieve_embeddings(DATA_SOURCE, SCHEMA=PG_SCHEMA)\n",
        "\n",
        "print(\"Table and Column embeddings are created\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üíæ **Save the Table and Column Embeddings in the Vector Store**\n",
        "The table and column embeddings created in the above step are save to the Vector Store chosen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Table and Column embeddings are saved to vector store\n"
          ]
        }
      ],
      "source": [
        "from embeddings.store_embeddings import store_schema_embeddings\n",
        "\n",
        "if VECTOR_STORE=='bigquery-vector':\n",
        "    await(store_schema_embeddings(table_details_embeddings=table_schema_embeddings, \n",
        "                                  tablecolumn_details_embeddings=col_schema_embeddings, \n",
        "                                  project_id=PROJECT_ID,\n",
        "                                  instance_name=None,\n",
        "                                  database_name=None,\n",
        "                                  schema=BQ_OPENDATAQNA_DATASET_NAME,\n",
        "                                  database_user=None,\n",
        "                                  database_password=None,\n",
        "                                  region=BQ_REGION,\n",
        "                                  VECTOR_STORE = VECTOR_STORE\n",
        "                                  ))\n",
        "\n",
        "elif VECTOR_STORE=='cloudsql-pgvector':\n",
        "    await(store_schema_embeddings(table_details_embeddings=table_schema_embeddings, \n",
        "                                tablecolumn_details_embeddings=col_schema_embeddings, \n",
        "                                project_id=PROJECT_ID,\n",
        "                                instance_name=PG_INSTANCE,\n",
        "                                database_name=PG_DATABASE,\n",
        "                                schema=None,\n",
        "                                database_user=PG_USER,\n",
        "                                database_password=PG_PASSWORD,\n",
        "                                region=PG_REGION,\n",
        "                                VECTOR_STORE = VECTOR_STORE\n",
        "                                ))\n",
        "\n",
        "print(\"Table and Column embeddings are saved to vector store\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üóÑÔ∏è **Load Known Good SQL into Vector Store**\n",
        "Known Good Queries are used to create query cache for Few shot examples. Creating a query cache is highly recommended for best outcomes! \n",
        "\n",
        "The following cell will load the Natural Language Question and Known Good SQL pairs into our Vector Store. There pairs are loaded from `known_good_sql.csv` file inside scripts folder. If you have your own Question-SQL examples, curate them in .csv file before running the cell below. \n",
        "\n",
        "If no Known Good Queries are available at this time to create query cache, you can use [3_LoadKnownGoodSQL.ipynb](3_LoadKnownGoodSQL.ipynb) to load them later!!\" Empty table for KGQ embedding will be created!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Format of the Known Good SQL File (known_good_sql.csv)\n",
        "\n",
        "prompt | sql | database_name [3 columns]\n",
        "\n",
        "prompt ==> User Question \n",
        "\n",
        "sql ==> SQL for the user question (Note that the sql should enclosed in quotes and only in single line. Please remove the line  break)\n",
        "\n",
        "database_name ==>This name should exactly  match the SCHEMA   NAME for Postgres Source or BQ_DATASET_NAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è WARNING: No Known Good Queries are provided to create query cache for Few shot examples!\n",
            "Creating a query cache is highly recommended for best outcomes\n",
            "If no Known Good Queries for the dataset are availabe at this time, you can use 3_LoadKnownGoodSQL.ipynb to load them later!!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if EXAMPLES :\n",
        "    print(\"Examples are provided, creating KGQ embeddings and saving them to Vector store.....\")\n",
        "\n",
        "    from embeddings.kgq_embeddings import setup_kgq_table, load_kgq_df, store_kgq_embeddings\n",
        "    import pandas as pd\n",
        "    \n",
        "    # Delete any old tables and create a new table to KGQ embeddings\n",
        "    if VECTOR_STORE=='bigquery-vector':\n",
        "        await(setup_kgq_table(project_id=PROJECT_ID,\n",
        "                            instance_name=None,\n",
        "                            database_name=None,\n",
        "                            schema=BQ_OPENDATAQNA_DATASET_NAME,\n",
        "                            database_user=None,\n",
        "                            database_password=None,\n",
        "                            region=BQ_REGION,\n",
        "                            VECTOR_STORE = VECTOR_STORE\n",
        "                            ))\n",
        "\n",
        "    elif VECTOR_STORE=='cloudsql-pgvector':\n",
        "        await(setup_kgq_table(project_id=PROJECT_ID,\n",
        "                            instance_name=PG_INSTANCE,\n",
        "                            database_name=PG_DATABASE,\n",
        "                            schema=None,\n",
        "                            database_user=PG_USER,\n",
        "                            database_password=PG_PASSWORD,\n",
        "                            region=PG_REGION,\n",
        "                            VECTOR_STORE = VECTOR_STORE\n",
        "                            ))\n",
        "\n",
        "\n",
        "    # Load the contents of the known_good_sql.csv file into a dataframe\n",
        "    df_kgq = load_kgq_df()\n",
        "\n",
        "\n",
        "\n",
        "    # Add KGQ to the vector store\n",
        "    if VECTOR_STORE=='bigquery-vector':\n",
        "        await(store_kgq_embeddings(df_kgq,\n",
        "                                   project_id=PROJECT_ID,\n",
        "                                    instance_name=None,\n",
        "                                    database_name=None,\n",
        "                                    schema=BQ_OPENDATAQNA_DATASET_NAME,\n",
        "                                    database_user=None,\n",
        "                                    database_password=None,\n",
        "                                    region=BQ_REGION,\n",
        "                                    VECTOR_STORE = VECTOR_STORE\n",
        "                                    ))\n",
        "\n",
        "    elif VECTOR_STORE=='cloudsql-pgvector':\n",
        "        await(store_kgq_embeddings(df_kgq,\n",
        "                                   project_id=PROJECT_ID,\n",
        "                                    instance_name=PG_INSTANCE,\n",
        "                                    database_name=PG_DATABASE,\n",
        "                                    schema=None,\n",
        "                                    database_user=PG_USER,\n",
        "                                    database_password=PG_PASSWORD,\n",
        "                                    region=PG_REGION,\n",
        "                                    VECTOR_STORE = VECTOR_STORE\n",
        "                                    ))\n",
        "    print('Done!!')\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è WARNING: No Known Good Queries are provided to create query cache for Few shot examples!\")\n",
        "    print(\"Creating a query cache is highly recommended for best outcomes\")\n",
        "    print(\"If no Known Good Queries for the dataset are availabe at this time, you can use 3_LoadKnownGoodSQL.ipynb to load them later!!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ü•Å If all the above steps are executed suucessfully, the following should be set up:\n",
        "\n",
        "* GCP project and all the required IAM permissions\n",
        "\n",
        "* Environment to run the solution\n",
        "\n",
        "* Data source and Vector store for the solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__________________________________________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **2. Run the Open Data QnA Pipeline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  ‚ùì **Ask your Natural Language Question**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mData Source:- bigquery\n",
            "Vector Store:- bigquery-vector\n",
            "Asked Question:- How many movies have a rating higher than four?\n"
          ]
        }
      ],
      "source": [
        "print(\"\\033[1mData Source:- \"+ DATA_SOURCE)\n",
        "print(\"Vector Store:- \"+ VECTOR_STORE)\n",
        "    \n",
        "# Suggested question for 'fda_food' dataset: \"What are the top 5 cities with highest recalls?\"\n",
        "# Suggested question for 'google_dei' dataset: \"How many asian men were part of the leadership workforce in 2021?\"\n",
        "\n",
        "# user_question = input(prompt_for_question) #Uncomment if you want to ask question yourself\n",
        "user_question = 'How many movies have a rating higher than four?' # Or Enter Question here\n",
        "\n",
        "print(\"Asked Question:- \"+user_question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üèÉ **Run the Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Agents.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting Data Source and Vector Store from config.ini content.\n",
            "Source selected is : bigquery\n",
            "Schema or Dataset Name is : imdb\n",
            "Vector Store selected is : bigquery-vector\n",
            "Found 5 similarity matches for table.\n",
            "Found 10 similarity matches for column.\n",
            "\n",
            "\n",
            " AUDIT_TEXT: \n",
            " \n",
            "User Question : How many movies have a rating higher than four?\n",
            "User Database : imdb\n",
            "\n",
            "Get Table and Column Schema: \n",
            "Retrieved Similar Known Good Queries, Table Schema and Column Schema: \n",
            "\n",
            "Retrieved Tables: \n",
            "\n",
            "            Full Table Name : msubasioglu-main.imdb.title_ratings |\n",
            "            Table Columns List: [tconst, average_rating, num_votes] |\n",
            "            Table Description: - **tconst**: Alphanumeric identifier for the title.\n",
            "- **average_rating**: Weighted average of all the user ratings.\n",
            "- **num_votes**: Number of votes the title has received. \n",
            "\n",
            "            Full Table Name : msubasioglu-main.imdb.reviews |\n",
            "            Table Columns List: [review, split, label, movie_id, reviewer_rating, movie_url, title] |\n",
            "            Table Description: - **label**: Review category with three possible values: Negative, Positive, or Unsupervised.\n",
            "- **movie_id**: Unique ID for the movie in IMDb.\n",
            "- **movie_url**: URL for the corresponding movie.\n",
            "- **review**: User review of the movie in IMDb.\n",
            "- **reviewer_rating**: Reviewer's rating for the movie in IMDb (null for unsupervised reviews).\n",
            "- **split**: Indicates whether the review is part of the training or test set.\n",
            "- **title**: Title of the movie. \n",
            "\n",
            "            Full Table Name : msubasioglu-main.imdb.title_principals |\n",
            "            Table Columns List: [tconst, ordering, nconst, category, job, characters] |\n",
            "            Table Description: - **category**: The category of job that person was in.\n",
            "- **characters**: The name of the character played if applicable.\n",
            "- **job**: The specific job title if applicable.\n",
            "- **nconst**: Alphanumeric unique identifier of the name/person.\n",
            "- **ordering**: A number to uniquely identify rows for a given title_id.\n",
            "- **tconst**: Alphanumeric unique identifier of the title. \n",
            "\n",
            "            Full Table Name : msubasioglu-main.imdb.title_crew |\n",
            "            Table Columns List: [tconst, directors, writers] |\n",
            "            Table Description: - **tconst**: Alphanumeric unique identifier of the title.\n",
            "- **directors**: String of nconsts - director(s) of the given title.\n",
            "- **writers**: String of nconsts - writer(s) of the given title. \n",
            "\n",
            "            Full Table Name : msubasioglu-main.imdb.title_basics |\n",
            "            Table Columns List: [tconst, title_type, primary_title, original_title, is_adult, start_year, end_year, runtime_minutes, genres] |\n",
            "            Table Description: | Column Name | Description |\n",
            "|---|---|\n",
            "| tconst | Unique identifier for each title. |\n",
            "| title_type | The type of title (e.g. movie, TV series, etc.). |\n",
            "| primary_title | The most popular title for the title. |\n",
            "| original_title | The original title for the title, in the original language. |\n",
            "| is_adult | Whether the title is an adult title (0=no, 1=yes). |\n",
            "| start_year | The release year of the title. |\n",
            "| end_year | The end year of the title (for TV series). |\n",
            "| runtime_minutes | The runtime of the title in minutes. |\n",
            "| genres | The genres associated with the title. | \n",
            "\n",
            "\n",
            "Retrieved Columns: \n",
            "\n",
            "            Column Name: imdb.title_ratings.num_votes|\n",
            "            Full Table Name : msubasioglu-main.imdb.title_ratings |\n",
            "            Data type: INT64|\n",
            "            Column description: Number of votes the title has received.|\n",
            "            Column Constraints: None \n",
            "\n",
            "            Column Name: imdb.title_basics.is_adult|\n",
            "            Full Table Name : msubasioglu-main.imdb.title_basics |\n",
            "            Data type: INT64|\n",
            "            Column description: 0: non-adult title; 1: adult title.|\n",
            "            Column Constraints: None \n",
            "\n",
            "            Column Name: imdb.title_ratings.tconst|\n",
            "            Full Table Name : msubasioglu-main.imdb.title_ratings |\n",
            "            Data type: STRING|\n",
            "            Column description: Alphanumeric unique identifier for title.|\n",
            "            Column Constraints: None \n",
            "\n",
            "            Column Name: imdb.reviews.reviewer_rating|\n",
            "            Full Table Name : msubasioglu-main.imdb.reviews |\n",
            "            Data type: INT64|\n",
            "            Column description: Reviewer rating for particular movie in IMDb. For train-unsupervised, reviewer_rating is NULL.|\n",
            "            Column Constraints: None \n",
            "\n",
            "            Column Name: imdb.title_ratings.average_rating|\n",
            "            Full Table Name : msubasioglu-main.imdb.title_ratings |\n",
            "            Data type: FLOAT64|\n",
            "            Column description: Weighted average of all the individual user ratings.|\n",
            "            Column Constraints: None \n",
            "\n",
            "            Column Name: imdb.title_principals.ordering|\n",
            "            Full Table Name : msubasioglu-main.imdb.title_principals |\n",
            "            Data type: INT64|\n",
            "            Column description: a number to uniquely identify rows for a given title_id.|\n",
            "            Column Constraints: None \n",
            "\n",
            "            Column Name: imdb.title_akas.ordering|\n",
            "            Full Table Name : msubasioglu-main.imdb.title_akas |\n",
            "            Data type: INT64|\n",
            "            Column description: A number to uniquely identify rows for a given title_id.|\n",
            "            Column Constraints: None \n",
            "\n",
            "            Column Name: imdb.title_basics.genres|\n",
            "            Full Table Name : msubasioglu-main.imdb.title_basics |\n",
            "            Data type: STRING|\n",
            "            Column description: Includes up to three genres associated with the title.|\n",
            "            Column Constraints: None \n",
            "\n",
            "            Column Name: imdb.reviews.title|\n",
            "            Full Table Name : msubasioglu-main.imdb.reviews |\n",
            "            Data type: STRING|\n",
            "            Column description: Title of the movie for corresponding movie_id|\n",
            "            Column Constraints: None \n",
            "\n",
            "            Column Name: imdb.title_basics.runtime_minutes|\n",
            "            Full Table Name : msubasioglu-main.imdb.title_basics |\n",
            "            Data type: INT64|\n",
            "            Column description: Primary runtime of the title, in minutes.|\n",
            "            Column Constraints: None \n",
            "\n",
            "\n",
            "Retrieved Known Good Queries: \n",
            "No similar SQLs provided...\n",
            "\n",
            "Build SQL: \n",
            "Generated SQL : SELECT\n",
            "  COUNT(*) AS num_movies\n",
            "FROM\n",
            "  `msubasioglu-main.imdb.title_ratings`\n",
            "WHERE\n",
            "  SAFE_CAST(average_rating AS INT64) > 4\n",
            "Final SQL after Debugger: \n",
            "SELECT\n",
            "  COUNT(*) AS num_movies\n",
            "FROM\n",
            "  `msubasioglu-main.imdb.title_ratings`\n",
            "WHERE\n",
            "  SAFE_CAST(average_rating AS INT64) > 4\n",
            "Not executing final SQL since EXECUTE_FINAL_SQL variable is False\n",
            " \n",
            "Final Answer:There are 218 movies with a rating higher than four.\n"
          ]
        }
      ],
      "source": [
        "from opendataqna import run_pipeline\n",
        "import asyncio \n",
        "\n",
        "final_sql, response, _resp = await(run_pipeline(user_question,\n",
        "                                                    VECTOR_STORE=VECTOR_STORE,\n",
        "                                                    DATA_SOURCE=DATA_SOURCE,  \n",
        "                                                    embedder='vertex',\n",
        "                                                    RUN_DEBUGGER=True,\n",
        "                                                    EXECUTE_FINAL_SQL=True,\n",
        "                                                    DEBUGGING_ROUNDS = 2, \n",
        "                                                    LLM_VALIDATION=True,\n",
        "                                                    Embedder_model='vertex',\n",
        "                                                    SQLBuilder_model= 'gemini-1.5-pro',\n",
        "                                                    SQLChecker_model= 'gemini-1.5-pro-001',\n",
        "                                                    SQLDebugger_model= 'gemini-1.5-pro-001',\n",
        "                                                    Responder_model= 'gemini-1.5-pro-001',\n",
        "                                                    num_table_matches = 5,\n",
        "                                                    num_column_matches = 10,\n",
        "                                                    table_similarity_threshold = 0.1,\n",
        "                                                    column_similarity_threshold = 0.1, \n",
        "                                                    example_similarity_threshold = 0.1, \n",
        "                                                    num_sql_matches=3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìä **Create Charts for the results** (Run only when you have proper results in the above cells)\n",
        "Agent provides two suggestive google charts to display on a UI with element IDs chart_div and chart_div_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Charts Suggested : ['Bar Chart', 'Table Chart']\n"
          ]
        }
      ],
      "source": [
        "from agents import VisualizeAgent\n",
        "Visualize = VisualizeAgent ()\n",
        "\n",
        "chart_js=''\n",
        "chart_js = Visualize.generate_charts(user_question,final_sql,response) #sending \n",
        "# print(chart_js[\"chart_div_1\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<script type=\"text/javascript\" src=\"https://www.gstatic.com/charts/loader.js\"></script>\n",
              "<script type=\"text/javascript\">\n",
              "google.charts.load('current', {packages: ['corechart']});\n",
              "google.charts.setOnLoadCallback(drawChart);\n",
              "    function drawChart() \n",
              "   {var data = google.visualization.arrayToDataTable([['Rating Range', 'Number of Movies'],\n",
              "     ['Higher than 4', 1380966]\n",
              "         \n",
              "         ]); \n",
              "         \n",
              "         var options =\n",
              "          { title: 'Number of Movies with a Rating Higher than 4',  \n",
              "           width: 600,   height: 300,    hAxis: {     \n",
              "           textStyle: {       fontSize: 12    } },  \n",
              "            vAxis: {     textStyle: {      fontSize: 12     }    },\n",
              "               legend: {    textStyle: {       fontSize: 12\n",
              "      }   },  \n",
              "                bar: {      groupWidth: '50%'    }  };\n",
              "                 var chart = new google.visualization.BarChart(document.getElementById('chart_div')); \n",
              "                  chart.draw(data, options);}\n",
              "</script>\n",
              "<div id=\"chart_div\"></div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "html_code = f'''\n",
        "<script type=\"text/javascript\" src=\"https://www.gstatic.com/charts/loader.js\"></script>\n",
        "<script type=\"text/javascript\">\n",
        "{chart_js[\"chart_div\"]}\n",
        "</script>\n",
        "<div id=\"chart_div\"></div>\n",
        "'''\n",
        "\n",
        "HTML(html_code)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<script type=\"text/javascript\" src=\"https://www.gstatic.com/charts/loader.js\"></script>\n",
              "<script type=\"text/javascript\">\n",
              "google.charts.load('current', {packages: ['table']});\n",
              "google.charts.setOnLoadCallback(drawTable);\n",
              "\n",
              "function drawTable() {\n",
              "  var data = new google.visualization.DataTable();\n",
              "  data.addColumn('string', 'Title');\n",
              "  data.addColumn('number', 'Rating');\n",
              "  data.addRows([\n",
              "    ['tt0000037', 4.5],\n",
              "    ['tt0000040', 4.1],\n",
              "    ['tt0000111', 4.4],\n",
              "    ['tt0000113', 4.3],\n",
              "    ['tt0000121', 4.2],\n",
              "    ['tt0111161', 4.0],\n",
              "    ['tt0113497', 4.1],\n",
              "    ['tt0167260', 4.2],\n",
              "    ['tt0167261', 4.2],\n",
              "    ['tt0167262', 4.1],\n",
              "    ['tt0211915', 4.2],\n",
              "    ['tt0211920', 4.0],\n",
              "    ['tt0212229', 4.0],\n",
              "    ['tt0261115', 4.0],\n",
              "    ['tt0266543', 4.1],\n",
              "    ['tt0266544', 4.1],\n",
              "    ['tt0268380', 4.1],\n",
              "    ['tt0269541', 4.1],\n",
              "    ['tt0287559', 4.0],\n",
              "    ['tt0289043', 4.1],\n",
              "    ['tt0289719', 4.0],\n",
              "    ['tt0293473', 4.1],\n",
              "    ['tt0295297', 4.0],\n",
              "    ['tt0297334', 4.1],\n",
              "    ['tt0297335', 4.0],\n",
              "    ['tt0298143', 4.1],\n",
              "    ['tt0301162', 4.1],\n",
              "    ['tt0303434', 4.0],\n",
              "    ['tt0304394', 4.0],\n",
              "    ['tt0317248', 4.1],\n",
              "    ['tt0317249', 4.1],\n",
              "    ['tt0320449', 4.0],\n",
              "    ['tt0324150', 4.1],\n",
              "    ['tt0325980', 4.1],\n",
              "    ['tt0329198', 4.0],\n",
              "    ['tt0332371', 4.0],\n",
              "    ['tt0332403', 4.1],\n",
              "    ['tt0334369', 4.0],\n",
              "    ['tt0334575', 4.0],\n",
              "    ['tt0338013', 4.0],\n",
              "    ['tt0338531', 4.1],\n",
              "    ['tt0343183', 4.1],\n",
              "    ['tt0345071', 4.0],\n",
              "    ['tt0347395', 4.0],\n",
              "    ['tt0350438', 4.1],\n",
              "    ['tt0353414', 4.0],\n",
              "    ['tt0357113', 4.0],\n",
              "    ['tt0361243', 4.1],\n",
              "    ['tt0363569', 4.0],\n",
              "    ['tt0366945', 4.0],\n",
              "    ['tt0367349', 4.1],\n",
              "    ['tt0367855', 4.0],\n",
              "    ['tt0368232', 4.0],\n",
              "    ['tt0372784', 4.1],\n",
              "    ['tt0373493', 4.1],\n",
              "    ['tt0373940', 4.0],\n",
              "    ['tt0381681', 4.1],\n",
              "    ['tt0383559', 4.0],\n",
              "    ['tt0383562', 4.1],\n",
              "    ['tt0385665', 4.1],\n",
              "    ['tt0392731', 4.1],\n",
              "    ['tt0394850', 4.1],\n",
              "    ['tt0400429', 4.1],\n",
              "    ['tt0405159', 4.1],\n",
              "    ['tt0405296', 4.0],\n",
              "    ['tt0405423', 4.1],\n",
              "    ['tt0407195', 4.0],\n",
              "    ['tt0407473', 4.1],\n",
              "    ['tt0412352', 4.0],\n",
              "    ['tt0414427', 4.1],\n",
              "    ['tt0424246', 4.1],\n",
              "    ['tt0425142', 4.1],\n",
              "    ['tt0429756', 4.1],\n",
              "    ['tt0434409', 4.1],\n",
              "    ['tt0434410', 4.1],\n",
              "    ['tt0435761', 4.0],\n",
              "    ['tt0437081', 4.0],\n",
              "    ['tt0441031', 4.1],\n",
              "    ['tt0441773', 4.0],\n",
              "    ['tt0443553', 4.0],\n",
              "    ['tt0448134', 4.1],\n",
              "    ['tt0451279', 4.1],\n",
              "    ['tt0454848', 4.0],\n",
              "    ['tt0457330', 4.1],\n",
              "    ['tt0457939', 4.1],\n",
              "    ['tt0464533', 4.0],\n",
              "    ['tt0468492', 4.0],\n",
              "    ['tt0472034', 4.1],\n",
              "    ['tt0474422', 4.0],\n",
              "    ['tt0479316', 4.0],\n",
              "    ['tt0479317', 4.1],\n",
              "    ['tt0480314', 4.1],\n",
              "    ['tt0482571', 4.1],\n",
              "    ['tt0484412', 4.0],\n",
              "    ['tt0490533', 4.1],\n",
              "    ['tt0499549', 4.1],\n",
              "    ['tt0500666', 4.1],\n",
              "    ['tt0501605', 4.0],\n",
              "    ['tt0504650', 4.0],\n",
              "    ['tt0507135', 4.0],\n",
              "    ['tt0511529', 4.0],\n",
              "    ['tt0512422', 4.1],\n",
              "    ['tt0524295', 4.1],\n",
              "    ['tt0524842', 4.1],\n",
              "    ['tt0529710', 4.1],\n",
              "    ['tt0534274', 4.1],\n",
              "    ['tt0534715', 4.1],\n",
              "    ['tt0541952', 4.0],\n",
              "    ['tt0543941', 4.0],\n",
              "    ['tt0543942', 4.0],\n",
              "    ['tt0548933', 4.0],\n",
              "    ['tt0550138', 4.0],\n",
              "    ['tt0554323', 4.0],\n",
              "    ['tt0558941', 4.1],\n",
              "    ['tt0562323', 4.0],\n",
              "    ['tt0562617', 4.0],\n",
              "    ['tt0567159', 4.1],\n",
              "    ['tt0568577', 4.1],\n",
              "    ['tt0568579', 4.0],\n",
              "    ['tt0574316', 4.1],\n",
              "    ['tt0581442', 4.1],\n",
              "    ['tt0582924', 4.1],\n",
              "    ['tt0583445', 4.1],\n",
              "    ['tt0583652', 4.0],\n",
              "    ['tt0583805', 4.0],\n",
              "    ['tt0587741', 4.0],\n",
              "    ['tt0587742', 4.0],\n",
              "    ['tt0588119', 4.1],\n",
              "    ['tt0591358', 4.1],\n",
              "    ['tt0594732', 4.1],\n",
              "    ['tt0603303', 4.1],\n",
              "    ['tt0603755', 4.1],\n",
              "    ['tt0605079', 4.1],\n",
              "    ['tt0606485', 4.1],\n",
              "    ['tt0611345', 4.0],\n",
              "    ['tt0612923', 4.1],\n",
              "    ['tt0613279', 4.1],\n",
              "    ['tt0615364', 4.1],\n",
              "    ['tt0621840', 4.0],\n",
              "    ['tt0622724', 4.0],\n",
              "    ['tt0627563', 4.1],\n",
              "    ['tt0632068', 4.1],\n",
              "    ['tt0634132', 4.1],\n",
              "    ['tt0634792', 4.0],\n",
              "    ['tt0641347', 4.1],\n",
              "    ['tt0643961', 4.1],\n",
              "    ['tt0646069', 4.0],\n",
              "    ['tt0651435', 4.0],\n",
              "    ['tt0657339', 4.1],\n",
              "    ['tt0657340', 4.0],\n",
              "    ['tt0657582', 4.0],\n",
              "    ['tt0664824', 4.1],\n",
              "    ['tt0665501', 4.0],\n",
              "    ['tt0669245', 4.0],\n",
              "    ['tt0673351', 4.0],\n",
              "    ['tt0680338', 4.1],\n",
              "    ['tt0683341', 4.0],\n",
              "    ['tt0691951', 4.1],\n",
              "    ['tt0704844', 4.1],\n",
              "    ['tt0705065', 4.1],\n",
              "    ['tt0705066', 4.1],\n",
              "    ['tt0710484', 4.0],\n",
              "    ['tt0710485', 4.1],\n",
              "    ['tt0714741', 4.1],\n",
              "    ['tt0715328', 4.1],\n",
              "    ['tt0719243', 4.1],\n",
              "    ['tt0720129', 4.1],\n",
              "    ['tt0721526', 4.1],\n",
              "    ['tt0725669', 4.0],\n",
              "    ['tt0728694', 4.1],\n",
              "    ['tt0729063', 4.0],\n",
              "    ['tt0731428', 4.1],\n",
              "    ['tt0733274', 4.0],\n",
              "    ['tt0737587', 4.0],\n",
              "    ['tt0741886', 4.0],\n",
              "    ['tt0746170', 4.1],\n",
              "    ['tt0748324', 4.1],\n",
              "    ['tt0758493', 4.1],\n",
              "    ['tt0758651', 4.0],\n",
              "    ['tt0762182', 4.1],\n",
              "    ['tt0762184', 4.1],\n",
              "    ['tt0762323', 4.0],\n",
              "    ['tt0762724', 4.1],\n",
              "    ['tt0764569', 4.1],\n",
              "    ['tt0770829', 4.1],\n",
              "    ['tt0770891', 4.0],\n",
              "    ['tt0770892', 4.0],\n",
              "    ['tt0770893', 4.1],\n",
              "    ['tt0780691', 4.1],\n",
              "    ['tt0788496', 4.1],\n",
              "    ['tt0792615', 4.0],\n",
              "    ['tt0801622', 4.0],\n",
              "    ['tt0803074', 4.1],\n",
              "    ['tt0805422', 4.1],\n",
              "    ['tt0810916', 4.1],\n",
              "    ['tt0813357', 4.1],\n",
              "    ['tt0813362', 4.0],\n",
              "    ['tt0816692', 4.0],\n",
              "    ['tt0822857', 4.0],\n",
              "    ['tt0825622', 4.1],\n",
              "    ['tt0826512', 4.1],\n",
              "    ['tt0836423', 4.0],\n",
              "    ['tt0837155', 4.0],\n",
              "    ['tt0848228', 4.1],\n",
              "    ['tt0852744', 4.0],\n",
              "    ['tt0855047', 4.1],\n",
              "    ['tt0855336', 4.1],\n",
              "    ['tt0862509', 4.1],\n",
              "    ['tt0867630', 4.1],\n",
              "    ['tt0867984', 4.1],\n",
              "    ['tt0868286', 4.1],\n",
              "    ['tt0868322', 4.1],\n",
              "    ['tt0869233', 4.1],\n",
              "    ['tt0872824', 4.0],\n",
              "    ['tt0873324', 4.1],\n",
              "    ['tt0877259', 4.1],\n",
              "    ['tt0882608', 4.1],\n",
              "    ['tt0884336', 4.0],\n",
              "    ['tt0892238', 4.1],\n",
              "    ['tt0894810', 4.0],\n",
              "    ['tt0894822', 4.0],\n",
              "    ['tt0898266', 4.1],\n",
              "    ['tt0903622', 4.1],\n",
              "    ['tt0905947', 4.0],\n",
              "    ['tt0908476', 4.0],\n",
              "    ['tt0909309', 4.1],\n",
              "    ['tt0910970', 4.0],\n",
              "    ['tt0910984', 4.1],\n",
              "    ['tt0910988', 4.0],\n",
              "    ['tt0910990', 4.1],\n",
              "    ['tt0912505', 4.1],\n",
              "    ['tt0912815', 4.0],\n",
              "    ['tt0912838', 4.1],\n",
              "    ['tt0914429', 4.1],\n",
              "    ['tt0917631', 4.1],\n",
              "    ['tt0920924', 4.1],\n",
              "    ['tt0925125', 4.1],\n",
              "    ['tt0926297', 4.0],\n",
              "    ['tt0936485', 4.0],\n",
              "    ['tt0942844', 4.0],\n",
              "    ['tt0944198', 4.1],\n",
              "    ['tt0944725', 4.1],\n",
              "    ['tt0944859', 4.0],\n",
              "    ['tt0947796', 4.0],\n",
              "    ['tt0951161', 4.1],\n",
              "    ['tt0953543', 4.0],\n",
              "    ['tt0954449', 4.0],\n",
              "    ['tt0954659', 4.1],\n",
              "    ['tt0956409', 4.1],\n",
              "    ['tt0956418', 4.1],\n",
              "    ['tt0968435', 4.1],\n",
              "    ['tt0975465', 4.1],\n",
              "    ['tt0975766', 4.0],\n",
              "    ['tt0978584', 4.1],\n",
              "    ['tt0982671', 4.0],\n",
              "    ['tt0982725', 4.1],\n",
              "    ['tt0982726', 4.0],\n",
              "    ['tt0984039', 4.1],\n",
              "    ['tt0985016', 4.0],\n",
              "    ['tt0990112', 4.1],\n",
              "    ['tt0992876', 4.1],\n",
              "    ['tt0994747', 4.0],\n",
              "    ['tt1001622', 4.1],\n",
              "    ['tt1001625', 4.0],\n",
              "    ['tt1003654', 4.1],\n",
              "    ['tt1003658', 4.1],\n",
              "    ['tt1003660', 4.1],\n",
              "    ['tt1004329', 4.0],\n",
              "    ['tt1004557', 4.1],\n",
              "    ['tt1004743', 4.1],\n",
              "    ['tt1004747', 4.1],\n",
              "    ['tt1004748', 4.0],\n",
              "    ['tt1008467', 4.1],\n",
              "    ['tt1010165', 4.0],\n",
              "    ['tt1011161', 4.0],\n",
              "    ['tt1012265', 4.1],\n",
              "    ['tt1013304', 4.1],\n",
              "    ['tt1014339', 4.1],\n",
              "    ['tt1014735', 4.0],\n",
              "    ['tt1014744', 4.1],\n",
              "    ['tt1014749', 4.1],\n",
              "    ['tt1014792', 4.1],\n",
              "    ['tt1018326', 4.1],\n",
              "    ['tt1018500', 4.1],\n",
              "    ['tt1024643', 4.1],\n",
              "    ['tt1025814', 4.1],\n",
              "    ['tt1026211', 4.0],\n",
              "    ['tt1027594', 4.0],\n",
              "    ['tt1027823', 4.1],\n",
              "    ['tt1031745', 4.0],\n",
              "    ['tt1034425', 4.1],\n",
              "    ['tt1035883', 4.0],\n",
              "    ['tt1042812', 4.1],\n",
              "    ['tt1048322', 4.0],\n",
              "    ['tt1049415', 4.1],\n",
              "    ['tt1049745', 4.0],\n",
              "    ['tt1052453', 4.1],\n",
              "    ['tt1052660', 4.0],\n",
              "    ['tt1052714', 4.1],\n",
              "    ['tt1052730', 4.1],\n",
              "    ['tt1054411', 4.1],\n",
              "    ['tt1058202', 4.0],\n",
              "    ['tt1065073', 4.1],\n",
              "    ['tt1069348', 4.1],\n",
              "    ['tt1069453', 4.1],\n",
              "    ['tt1071791', 4.0],\n",
              "    ['tt1073751', 4.1],\n",
              "    ['tt1073923', 4.0],\n",
              "    ['tt1074234', 4.1],\n",
              "    ['tt1074685', 4.1],\n",
              "    ['tt1075244', 4.1],\n",
              "    ['tt1075534', 4.1],\n",
              "    ['tt1076246', 4.0],\n",
              "    ['tt1077232', 4.0],\n",
              "    ['tt1078228', 4.1],\n",
              "    ['tt1081411', 4.0],\n",
              "    ['tt1083594', 4.1],\n",
              "    ['tt1083611', 4.1],\n",
              "    ['tt1085401', 4.1],\n",
              "    ['tt1086154', 4.0],\n",
              "    ['tt1087260', 4.1],\n",
              "    ['tt1088128', 4.0],\n",
              "    ['tt1088140', 4.1],\n",
              "    ['tt1088149', 4.1],\n",
              "    ['tt1091647', 4.1],\n",
              "    ['tt1094494', 4.1],\n",
              "    ['tt1094870', 4.0],\n",
              "    ['tt1096553', 4.0],\n",
              "    ['tt1098332', 4.1],\n",
              "    ['tt1098333', 4.0],\n",
              "    ['tt1099483', 4.1],\n",
              "    ['tt1102615', 4.1],\n",
              "    ['tt1104001', 4.1],\n",
              "    ['tt1105769', 4.0],\n",
              "    ['tt1109128', 4.1],\n",
              "    ['tt1109587', 4.0],\n",
              "    ['tt1113247', 4.1],\n",
              "    ['tt1117973', 4.1],\n",
              "    ['tt1118620', 4.1],\n",
              "    ['tt1119631', 4.1],\n",
              "    ['tt1120914', 4.1],\n",
              "    ['tt1123858', 4.0],\n",
              "    ['tt1125956', 4.1],\n",
              "    ['tt1125957', 4.0],\n",
              "    ['tt1128500', 4.1],\n",
              "    ['tt1130884', 4.1],\n",
              "    ['tt1132398', 4.1],\n",
              "    ['tt1134099', 4.1],\n",
              "    ['tt1136349', 4.1],\n",
              "    ['tt1136669', 4.0],\n",
              "    ['tt1136942', 4.1],\n",
              "    ['tt1140407', 4.0],\n",
              "    ['tt1141097', 4.1],\n",
              "    ['tt1143817', 4.0],\n",
              "    ['tt1144415', 4.0],\n",
              "    ['tt1144709', 4.1],\n",
              "    ['tt1146514', 4.1],\n",
              "    ['tt1150257', 4.0],\n",
              "    ['tt1150330', 4.1],\n",
              "    ['tt1150440', 4.1],\n",
              "    ['tt1152424', 4.0],\n",
              "    ['tt1154251', 4.1],\n",
              "    ['tt1156519', 4.1],\n",
              "    ['tt1158022', 4.0],\n",
              "    ['tt1158425', 4.1],\n",
              "    ['tt1160263', 4.1],\n",
              "    ['tt1161199', 4.0],\n",
              "    ['tt1162847', 4.1],\n",
              "    ['tt1163927', 4.0],\n",
              "    ['tt1166323', 4.1],\n",
              "    ['tt1166342', 4.1],\n",
              "    ['tt1168643', 4.0],\n",
              "    ['tt1171564', 4.1],\n",
              "    ['tt1173275', 4.1],\n",
              "    ['tt1175576', 4.1],\n",
              "    ['tt1177008', 4.1],\n",
              "    ['tt1178254', 4.1],\n",
              "    ['tt1181245', 4.1],\n",
              "    ['tt1181246', 4.0],\n",
              "    ['tt1182221', 4.1],\n",
              "    ['tt1182623', 4.1],\n",
              "    ['tt1182660', 4.1],\n",
              "    ['tt1186441', 4.1],\n",
              "    ['tt1186601', 4.0],\n",
              "    ['tt1187032', 4.1],\n",
              "    ['tt1190536', 4.0],\n",
              "    ['tt1190919', 4.0],\n",
              "    ['tt1190981', 4.1],\n",
              "    ['tt1191111', 4.1],\n",
              "    ['tt1192429', 4.1],\n",
              "    ['tt1193285', 4.0],\n",
              "    ['tt1194351', 4.1],\n",
              "    ['tt1194386', 4.1],\n",
              "    ['tt1195922', 4.1],\n",
              "    ['tt1198493', 4.0],\n",
              "    ['tt1198504', 4.1],\n",
              "    ['tt1201607', 4.1],\n",
              "    ['tt1205489', 4.1],\n",
              "    ['tt1205490', 4.1],\n",
              "    ['tt1205494', 4.1],\n",
              "    ['tt1205497', 4.0],\n",
              "    ['tt1205863', 4.1],\n",
              "    ['tt1206832', 4.0],\n",
              "    ['tt1206833', 4.1],\n",
              "    ['tt1206875', 4.1],\n",
              "    ['tt1209033', 4.0],\n",
              "    ['tt1209131', 4.0],\n",
              "    ['tt1210165', 4.1],\n",
              "    ['tt1211837', 4.0],\n",
              "    ['tt1211838', 4.1],\n",
              "    ['tt1211937', 4.0],\n",
              "    ['tt1213838', 4.1],\n",
              "    ['tt1215532', 4.0],\n",
              "    ['tt1215544', 4.0],\n",
              "    ['tt1220321', 4.1],\n",
              "    ['tt1220548', 4.1],\n",
              "    ['tt1220903', 4.1],\n",
              "    ['tt1222753', 4.0],\n",
              "    ['tt1222754', 4.1],\n",
              "    ['tt1229340', 4.1],\n",
              "    ['tt1229683', 4.1],\n",
              "    ['tt1230160', 4.0],\n",
              "    ['tt1231503', 4.1],\n",
              "    ['tt1232829', 4.0],\n",
              "    ['tt1232838', 4.0],\n",
              "    ['tt1232992', 4.1],\n",
              "    ['tt1233332', 4.1],\n",
              "    ['tt1234885', 4.1],\n",
              "    ['tt1236423', 4.1],\n",
              "    ['tt1236425', 4.0],\n",
              "    ['tt1236454', 4.1],\n",
              "    ['tt1240172', 4.1],\n",
              "    ['tt1240833', 4.0],\n",
              "    ['tt1241038', 4.0],\n",
              "    ['tt1242828', 4.0],\n",
              "    ['tt1242841', 4.1],\n",
              "    ['tt1244234', 4.1],\n",
              "    ['tt1246593', 4.0],\n",
              "    ['tt1247060', 4.1],\n",
              "    ['tt1248205', 4.0],\n",
              "    ['tt1250753', 4.1],\n",
              "    ['tt1251215', 4.0],\n",
              "    ['tt1252561', 4.0],\n",
              "    ['tt1252755', 4.0],\n",
              "    ['tt1254378', 4.1],\n",
              "    ['tt1255920', 4.1],\n",
              "    ['tt1256161', 4.1],\n",
              "    ['tt1256164', 4.0],\n",
              "    ['tt1256529', 4.1],\n",
              "    ['tt1257358', 4.1],\n",
              "    ['tt1259561', 4.0],\n",
              "    ['tt1259878', 4.0],\n",
              "    ['tt1260433', 4.1],\n",
              "    ['tt1261257', 4.1],\n",
              "    ['tt1262814', 4.1],\n",
              "    ['tt1264952', 4.1],\n",
              "    ['tt1269723', 4.1],\n",
              "    ['tt1270066', 4.1],\n",
              "    ['tt1270078', 4.1],\n",
              "    ['tt1270748', 4.0],\n",
              "    ['tt1272877', 4.1],\n",
              "    ['tt1273843', 4.0],\n",
              "    ['tt1273848', 4.1],\n",
              "    ['tt1275963', 4.0],\n",
              "    ['tt1276547', 4.1],\n",
              "    ['tt1276581', 4.1],\n",
              "    ['tt1277423', 4.0],\n",
              "    ['tt1278253', 4.1],\n",
              "    ['tt1279150', 4.0],\n",
              "    ['tt1279363', 4.1],\n",
              "    ['tt1279458', 4.1],\n",
              "    ['tt1279620', 4.0],\n",
              "    ['tt1280126', 4.1],\n",
              "    ['tt1280558', 4.0],\n",
              "    ['tt1280559', 4.1],\n",
              "    ['tt1281570', 4.1],\n",
              "    ['tt1281572', 4.1],\n",
              "    ['tt12829\n",
              "</script>\n",
              "<div id=\"chart_div_1\"></div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "html_code = f'''\n",
        "<script type=\"text/javascript\" src=\"https://www.gstatic.com/charts/loader.js\"></script>\n",
        "<script type=\"text/javascript\">\n",
        "{chart_js[\"chart_div_1\"]}\n",
        "</script>\n",
        "<div id=\"chart_div_1\"></div>\n",
        "'''\n",
        "\n",
        "HTML(html_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üóë **Clean Up Notebook Resources**\n",
        "Make sure to delete your Cloud SQL instance and BigQuery Datasets when your are finished with this notebook to avoid further costs. üí∏ üí∞\n",
        "\n",
        "Uncomment and run the cell below to delete "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # delete Cloud SQL instance\n",
        "# !gcloud sql instances delete {PG_INSTANCE} -q\n",
        "\n",
        "# #delete BigQuery Dataset using bq utility\n",
        "# !bq rm -r -f -d {BQ_DATASET_NAME}\n",
        "\n",
        "# #delete BigQuery 'Open Data QnA' Vector Store Dataset using bq utility\n",
        "\n",
        "# !bq rm -r -f -d {BQ_OPENDATAQNA_DATASET_NAME}\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
