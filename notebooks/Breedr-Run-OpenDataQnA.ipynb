{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: left;\">\n",
    "    <a href=\"https://sites.google.com/corp/google.com/genai-solutions/home?authuser=0\">\n",
    "        <img src=\"https://storage.googleapis.com/miscfilespublic/Linkedin%20Banner%20%E2%80%93%202.png\" style=\"margin-right\">\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **Open Data QnA**\n",
    "\n",
    "---\n",
    "\n",
    "This notebook assumes you have already Setup Vector Store and Variables are assigned in Config.ini file\n",
    "\n",
    "\n",
    "The notebook covers the following steps: \n",
    "\n",
    "> 1. Take user question and generate sql in the dialect corresponding to data source\n",
    "\n",
    "> 2. Execute the sql query and retreive the data\n",
    "\n",
    "> 3. Generate natural language respose and charts to display\n",
    "\n",
    "> 4. Clean Up resources\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš§ **0. Pre-requisites**\n",
    "\n",
    "Make sure that you have completed the intial setup process using [1_SetUpVectorStore.ipynb](1_SetUpVectorStore.ipynb). If the 1_SetUpVectorStore notebook has been run successfully, the following are set up:\n",
    "* GCP project and all the required IAM permissions\n",
    "\n",
    "* Environment to run the solution\n",
    "\n",
    "* Data source and Vector store for the solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ **1. Retrieve Configuration Parameters**\n",
    "The notebook will load all the configuration parameters from the `config.ini` file in the root directory. \n",
    "Most of these parameters were set in the initial notebook `1_SetUpVectorStore.ipynb` and save to the 'config.ini file.\n",
    "Use the below cells to retrieve these values and specify additional ones required for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(module_path)\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(module_path+'/config.ini')\n",
    "\n",
    "PROJECT_ID = config['GCP']['PROJECT_ID']\n",
    "DATA_SOURCE = config['CONFIG']['DATA_SOURCE']\n",
    "VECTOR_STORE = config['CONFIG']['VECTOR_STORE']\n",
    "\n",
    "BQ_OPENDATAQNA_DATASET_NAME = config['BIGQUERY']['BQ_OPENDATAQNA_DATASET_NAME']\n",
    "BQ_LOG_TABLE_NAME = config['BIGQUERY']['BQ_LOG_TABLE_NAME'] \n",
    "BQ_DATASET_REGION = config['BIGQUERY']['BQ_DATASET_REGION']\n",
    "BQ_DATASET_NAME = config['BIGQUERY']['BQ_DATASET_NAME']\n",
    "BQ_TABLE_LIST = config['BIGQUERY']['BQ_TABLE_LIST']\n",
    "\n",
    "#The Postgress settings are not used, but some of the API calls below depend on them being set.\n",
    "PG_SCHEMA = config['PGCLOUDSQL']['PG_SCHEMA']\n",
    "PG_DATABASE = config['PGCLOUDSQL']['PG_DATABASE']\n",
    "PG_USER = config['PGCLOUDSQL']['PG_USER']\n",
    "PG_REGION = config['PGCLOUDSQL']['PG_REGION'] \n",
    "PG_INSTANCE = config['PGCLOUDSQL']['PG_INSTANCE'] \n",
    "PG_PASSWORD = config['PGCLOUDSQL']['PG_PASSWORD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ” **2. Authenticate and Connect to Google Cloud Project**\n",
    "Authenticate to Google Cloud as the IAM user logged into this notebook in order to access your Google Cloud Project.\n",
    "\n",
    "You can do this within Google Colab or using the Application Default Credentials in the Google Cloud CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Project has been set to uk-bh-experiments-argolis\n",
      "\n",
      "Credentials saved to file: [/home/brendanhills/.config/gcloud/application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "\n",
      "Quota project \"uk-bh-experiments-argolis\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Colab Auth\"\"\" \n",
    "# from google.colab import auth\n",
    "# auth.authenticate_user()\n",
    "\n",
    "\n",
    "\"\"\"Google CLI Auth\"\"\"\n",
    "# !gcloud auth application-default login\n",
    "\n",
    "\n",
    "import google.auth\n",
    "credentials, project_id = google.auth.default()\n",
    "\n",
    "# Configure gcloud.\n",
    "!gcloud config set project {PROJECT_ID}\n",
    "print(f'Project has been set to {PROJECT_ID}')\n",
    "!gcloud auth application-default set-quota-project {PROJECT_ID}\n",
    "\n",
    "import os\n",
    "os.environ['GOOGLE_CLOUD_QUOTA_PROJECT']=PROJECT_ID\n",
    "os.environ['GOOGLE_CLOUD_PROJECT']=PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ï¸ **3. Run the Open Data QnA Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”— **3A. Connect to Datasource, Vector Source and Vertex AI**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dir:  /home/brendanhills/dev/applied-ai-engineering-samples/notebooks\n",
      "root_dir set to: /home/brendanhills/dev/applied-ai-engineering-samples\n",
      "Source selected is : bigquery\n",
      "Schema or Dataset Name is : breedr\n",
      "Vector Store selected is : bigquery-vector\n",
      "Creating agent with model_id: gemini-1.0-pro\n",
      "Creating agent with model_id: gemini-1.0-pro\n",
      "Creating agent with model_id: gemini-1.0-pro\n"
     ]
    }
   ],
   "source": [
    "# Fetch the USER_DATABASE based on data source\n",
    "from dbconnectors import pgconnector, bqconnector\n",
    "if DATA_SOURCE=='bigquery':\n",
    "    USER_DATABASE=BQ_DATASET_NAME \n",
    "    src_connector = bqconnector\n",
    "else: \n",
    "    USER_DATABASE=PG_SCHEMA\n",
    "    src_connector = pgconnector\n",
    "\n",
    "print(\"Source selected is : \"+ str(DATA_SOURCE) + \"\\nSchema or Dataset Name is : \"+ str(USER_DATABASE))\n",
    "print(\"Vector Store selected is : \"+ str(VECTOR_STORE))\n",
    "\n",
    "\n",
    "# Set the vector store paramaters\n",
    "if VECTOR_STORE=='bigquery-vector':\n",
    "    region=BQ_DATASET_REGION\n",
    "    vector_connector = bqconnector\n",
    "    call_await = False\n",
    "\n",
    "else:\n",
    "    region=PG_REGION\n",
    "    vector_connector = pgconnector\n",
    "    call_await=True\n",
    "\n",
    "\n",
    "num_table_matches = 5\n",
    "num_column_matches = 10\n",
    "similarity_threshold = 0.3\n",
    "num_sql_matches=3\n",
    "\n",
    "\n",
    "RUN_DEBUGGER = True \n",
    "EXECUTE_FINAL_SQL = True \n",
    "\n",
    "from google.api_core.exceptions import NotFound\n",
    "from google.cloud import aiplatform\n",
    "import vertexai\n",
    "\n",
    "from agents import EmbedderAgent, BuildSQLAgent, DebugSQLAgent, ValidateSQLAgent, ResponseAgent, VisualizeAgent\n",
    "\n",
    "\n",
    "embedder = EmbedderAgent('vertex') \n",
    "\n",
    "SQLBuilder = BuildSQLAgent('gemini-1.0-pro')\n",
    "SQLChecker = ValidateSQLAgent('gemini-1.0-pro')\n",
    "SQLDebugger = DebugSQLAgent('gemini-1.0-pro')\n",
    "Responder = ResponseAgent('gemini-1.0-pro')\n",
    "Visualize = VisualizeAgent ()\n",
    "\n",
    "found_in_vector = 'N'\n",
    "final_sql='Not Generated Yet'\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=region)\n",
    "aiplatform.init(project=PROJECT_ID, location=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  â“ **3B. Ask your Natural Language Question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mData Source:- bigquery\n",
      "Vector Store:- bigquery-vector\n",
      "Schema:- breedr\n",
      "Asked database breedr the WHich animal was the heaviest?\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1mData Source:- \"+ DATA_SOURCE)\n",
    "print(\"Vector Store:- \"+ VECTOR_STORE)\n",
    "print(\"Schema:- \"+USER_DATABASE)\n",
    "    \n",
    "# Suggested question for 'fda_food' dataset: \"What are the top 5 cities with highest recalls?\"\n",
    "#  Suggested question for 'google_dei' dataset: \"How many asian men were part of the leadership workforce in 2021?\"\n",
    "\n",
    "prompt_for_question = \"Please enter your question for source :\" + DATA_SOURCE + \" and database : \" + USER_DATABASE\n",
    "user_question = input(prompt_for_question) #Uncomment if you want to ask question yourself\n",
    "#user_question = '' # Or Enter Question here\n",
    "\n",
    "print(f\"Asked database {USER_DATABASE} the {user_question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No exact match found for the user prompt\n",
      "Did not find any results for example. Adjust the query parameters.\n",
      "Found 1 similarity matches for table.\n",
      "Found 10 similarity matches for column.\n",
      "```sql\n",
      "SELECT\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.animal_subtype,\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.kill_fat_score,\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.kill_fat_score_int,\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.kill_quality_int,\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.kill_weight,\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.name,\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.pedigree\n",
      "  FROM\n",
      "    `uk-bh-experiments-argolis.breedr.animals` AS `uk-bh-experiments-argolis.breedr.animals`\n",
      "  WHERE `uk-bh-experiments-argolis.breedr.animals`.kill_weight IS NOT NULL\n",
      "   AND `uk-bh-experiments-argolis.breedr.animals`.kill_fat_score IS NOT NULL\n",
      "   AND `uk-bh-experiments-argolis.breedr.animals`.kill_fat_score_int IS NOT NULL\n",
      "   AND `uk-bh-experiments-argolis.breedr.animals`.kill_quality_int IS NOT NULL\n",
      "   AND `uk-bh-experiments-argolis.breedr.animals`.animal_subtype IS NOT NULL\n",
      "   AND `uk-bh-experiments-argolis.breedr.animals`.name IS NOT NULL\n",
      "   AND `uk-bh-experiments-argolis.breedr.animals`.pedigree IS NOT NULL\n",
      "ORDER BY\n",
      "  `uk-bh-experiments-argolis.breedr.animals`.kill_weight DESC\n",
      "LIMIT 1\n",
      "```\n",
      "This query will process 1903 bytes.\n",
      "exec_result_df:This query will process 1903 bytes.\n",
      "\n",
      "\n",
      " AUDIT_TEXT: \n",
      " \n",
      "User Question : WHich animal was the heaviest?\n",
      "User Database : breedr\n",
      "\n",
      "Get Exact Match: \n",
      "No exact match found in query cache, retreiving revelant schema and known good queries for few shot examples using similarity search....\n",
      "\n",
      "Get Table and Column Schema: \n",
      "Retrieved Similar Known Good Queries, Table Schema and Column Schema: \n",
      "\n",
      "Retrieved Tables: \n",
      "\n",
      "            Full Table Name : uk-bh-experiments-argolis.breedr.animals |\n",
      "            Table Columns List: [id, group_id, breeding, children, dob, kill_weight, name, visual_ids_history, registration_status, related_meat_labels, is_castrated, is_male, pedigree, sire_is_pedigree, sire_studs, stud_sired_id, visual_id, dam_id, sire_id, description, breed_society_registration, e_id, passport_number, dead_at, owners_history, owner_id, animal_type_id, e_ids_history, is_pedigree, link_to_origin_animal_id, created_at, updated_at, dam_passport_number, sire_passport_number, is_on_farm, date_left_farm, date_moved_to_farm, animal_subtype, is_regulatory_synced, lot_id, link_to_my_sire_id, birth_information_id, field_id, meta_data, location_id, updated_by_id, last_regulatory_synced_date, animal_colour_id, kill_fat_score, kill_quality, kill_fat_score_int, kill_quality_int, is_birthed, dam_passport_number_cleaned, e_id_cleaned, passport_number_cleaned, sire_passport_number_cleaned, is_pregnant, pregnancy_due_date, is_owned_by_impact, impact_status, is_soft_deleted, soft_deleted_at] |\n",
      "            Table Description: ## Animals Table Description\n",
      "This table stores information about animals, including their id, group, breeding status, offspring count, date of birth, kill weight, name, visual identification history, registration status, meat labels, castration status, sex, pedigree information, sire's pedigree and stud status, visual identification, dam and sire IDs, description, breed society registration, electronic identification, passport number, death date, owner history, current owner ID, animal type ID, electronic identification history, pedigree status, link to origin animal, creation and update timestamps, dam and sire passport numbers, on-farm status, left and moved farm dates, animal subtype, regulatory sync status, lot ID, link to my sire ID, birth information ID, field ID, metadata, location ID, updated by ID, last regulatory sync date, animal colour ID, kill fat score and quality, kill fat and quality scores as integers, birthing status, cleaned dam and electronic identification passport numbers, pregnancy status and due date, owned by impact status, impact status, soft deleted status and timestamp. \n",
      " \n",
      "\n",
      "\n",
      "Retrieved Columns: \n",
      "\n",
      "            Column Name: breedr.animals.kill_weight|\n",
      "            Full Table Name : uk-bh-experiments-argolis.breedr.animals |\n",
      "            Data type: FLOAT64|\n",
      "            Column description: ## Description for kill_weight:\n",
      "\n",
      "Float value representing the animal's weight at the time of slaughter. May be null for animals not yet killed.\n",
      "|\n",
      "            Column Constraints: None \n",
      "\n",
      "            Column Name: breedr.animals.kill_fat_score_int|\n",
      "            Full Table Name : uk-bh-experiments-argolis.breedr.animals |\n",
      "            Data type: FLOAT64|\n",
      "            Column description: ## Kill Fat Score as Integer\n",
      "\n",
      "This column stores the kill fat score of the animal as an integer. The data type is FLOAT64. \n",
      "|\n",
      "            Column Constraints: None \n",
      "\n",
      "            Column Name: breedr.animals.children|\n",
      "            Full Table Name : uk-bh-experiments-argolis.breedr.animals |\n",
      "            Data type: FLOAT64|\n",
      "            Column description: ## Number of offspring for each animal. \n",
      "\n",
      "This column, of data type FLOAT64, represents the number of offspring each animal has had. \n",
      "|\n",
      "            Column Constraints: None \n",
      "\n",
      "            Column Name: breedr.animals.animal_subtype|\n",
      "            Full Table Name : uk-bh-experiments-argolis.breedr.animals |\n",
      "            Data type: FLOAT64|\n",
      "            Column description: The animal_subtype column stores a numerical value representing the animal's subtype. The specific subtypes represented by the values are not defined in the provided table information. \n",
      "|\n",
      "            Column Constraints: None \n",
      "\n",
      "            Column Name: breedr.animals.kill_fat_score|\n",
      "            Full Table Name : uk-bh-experiments-argolis.breedr.animals |\n",
      "            Data type: STRING|\n",
      "            Column description: ## Kill fat score assigned to the animal post-mortem. (String) \n",
      "\n",
      "**Note:** This column stores the subjective kill fat score assigned to the animal after slaughter, which may not be a numerical value. \n",
      "|\n",
      "            Column Constraints: None \n",
      "\n",
      "            Column Name: breedr.animals.description|\n",
      "            Full Table Name : uk-bh-experiments-argolis.breedr.animals |\n",
      "            Data type: FLOAT64|\n",
      "            Column description: ## Description for column `uk-bh-experiments-argolis.breedr.animals.description`\n",
      "\n",
      "This FLOAT64 column stores an animal's description, potentially including details like physical attributes, breed information, and temperament.|\n",
      "            Column Constraints: None \n",
      "\n",
      "            Column Name: breedr.medicine_vmd_data.target_species|\n",
      "            Full Table Name : uk-bh-experiments-argolis.breedr.medicine_vmd_data |\n",
      "            Data type: FLOAT64|\n",
      "            Column description: ## `target_species`: FLOAT64\n",
      "\n",
      "This column indicates the intended target species for the veterinary medicine. It is a numerical representation of a species classification.|\n",
      "            Column Constraints: None \n",
      "\n",
      "            Column Name: breedr.animals.kill_quality_int|\n",
      "            Full Table Name : uk-bh-experiments-argolis.breedr.animals |\n",
      "            Data type: FLOAT64|\n",
      "            Column description: ## Description:\n",
      "\n",
      "This column stores the kill quality score as an integer. (type: FLOAT64) \n",
      "|\n",
      "            Column Constraints: None \n",
      "\n",
      "            Column Name: breedr.animals.pedigree|\n",
      "            Full Table Name : uk-bh-experiments-argolis.breedr.animals |\n",
      "            Data type: FLOAT64|\n",
      "            Column description: ## Animals pedigree (FLOAT64)\n",
      "\n",
      "This column stores the pedigree value for each animal, indicating its percentage of purebred lineage.|\n",
      "            Column Constraints: None \n",
      "\n",
      "            Column Name: breedr.animals.name|\n",
      "            Full Table Name : uk-bh-experiments-argolis.breedr.animals |\n",
      "            Data type: FLOAT64|\n",
      "            Column description: This column represents individual animal names within the Argos dataset. It is a string column potentially containing alphanumeric characters and special symbols. \n",
      "|\n",
      "            Column Constraints: None \n",
      "\n",
      "\n",
      "Retrieved Known Good Queries: \n",
      "\n",
      "\n",
      "Build SQL: \n",
      "Generated SQL : ```sql\n",
      "SELECT\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.animal_subtype,\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.kill_fat_score,\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.kill_fat_score_int,\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.kill_quality_int,\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.kill_weight,\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.name,\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.pedigree\n",
      "  FROM\n",
      "    `uk-bh-experiments-argolis.breedr.animals` AS `uk-bh-experiments-argolis.breedr.animals`\n",
      "  WHERE `uk-bh-experiments-argolis.breedr.animals`.kill_weight IS NOT NULL\n",
      "   AND `uk-bh-experiments-argolis.breedr.animals`.kill_fat_score IS NOT NULL\n",
      "   AND `uk-bh-experiments-argolis.breedr.animals`.kill_fat_score_int IS NOT NULL\n",
      "   AND `uk-bh-experiments-argolis.breedr.animals`.kill_quality_int IS NOT NULL\n",
      "   AND `uk-bh-experiments-argolis.breedr.animals`.animal_subtype IS NOT NULL\n",
      "   AND `uk-bh-experiments-argolis.breedr.animals`.name IS NOT NULL\n",
      "   AND `uk-bh-experiments-argolis.breedr.animals`.pedigree IS NOT NULL\n",
      "ORDER BY\n",
      "  `uk-bh-experiments-argolis.breedr.animals`.kill_weight DESC\n",
      "LIMIT 1\n",
      "```\n",
      "\n",
      "Entering the debugging steps!\n",
      "Generated SQL is syntactically correct as per LLM Validation!\n",
      "Final SQL after Debugger: \n",
      "\n",
      "SELECT\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.animal_subtype,\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.kill_fat_score,\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.kill_fat_score_int,\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.kill_quality_int,\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.kill_weight,\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.name,\n",
      "    `uk-bh-experiments-argolis.breedr.animals`.pedigree\n",
      "  FROM\n",
      "    `uk-bh-experiments-argolis.breedr.animals` AS `uk-bh-experiments-argolis.breedr.animals`\n",
      "  WHERE `uk-bh-experiments-argolis.breedr.animals`.kill_weight IS NOT NULL\n",
      "   AND `uk-bh-experiments-argolis.breedr.animals`.kill_fat_score IS NOT NULL\n",
      "   AND `uk-bh-experiments-argolis.breedr.animals`.kill_fat_score_int IS NOT NULL\n",
      "   AND `uk-bh-experiments-argolis.breedr.animals`.kill_quality_int IS NOT NULL\n",
      "   AND `uk-bh-experiments-argolis.breedr.animals`.animal_subtype IS NOT NULL\n",
      "   AND `uk-bh-experiments-argolis.breedr.animals`.name IS NOT NULL\n",
      "   AND `uk-bh-experiments-argolis.breedr.animals`.pedigree IS NOT NULL\n",
      "ORDER BY\n",
      "  `uk-bh-experiments-argolis.breedr.animals`.kill_weight DESC\n",
      "LIMIT 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetch the embedding of the user's input question \n",
    "embedded_question = embedder.create(user_question)\n",
    "\n",
    "# Reset AUDIT_TEXT\n",
    "AUDIT_TEXT = ''\n",
    "\n",
    "AUDIT_TEXT = AUDIT_TEXT + \"\\nUser Question : \" + str(user_question) + \"\\nUser Database : \" + str(USER_DATABASE)\n",
    "process_step = \"\\n\\nGet Exact Match: \"\n",
    "# Look for exact matches in known questions \n",
    "exact_sql_history = vector_connector.getExactMatches(user_question) \n",
    "\n",
    "if exact_sql_history is not None:\n",
    "    found_in_vector = 'Y' \n",
    "    final_sql = exact_sql_history\n",
    "    invalid_response = False\n",
    "    AUDIT_TEXT = AUDIT_TEXT + \"\\nExact match has been found! Going to retreive the SQL query from cache and serve!\"\n",
    "\n",
    "\n",
    "else:\n",
    "    # No exact match found. Proceed looking for similar entries in db \n",
    "    AUDIT_TEXT = AUDIT_TEXT +  process_step + \"\\nNo exact match found in query cache, retreiving revelant schema and known good queries for few shot examples using similarity search....\"\n",
    "    process_step = \"\\n\\nGet Similar Match: \"\n",
    "    if call_await:\n",
    "        similar_sql = await vector_connector.getSimilarMatches('example', USER_DATABASE, embedded_question, num_sql_matches, similarity_threshold)\n",
    "    else:\n",
    "        similar_sql = vector_connector.getSimilarMatches('example', USER_DATABASE, embedded_question, num_sql_matches, similarity_threshold)\n",
    "\n",
    "    process_step = \"\\n\\nGet Table and Column Schema: \"\n",
    "    # Retrieve matching tables and columns\n",
    "    if call_await: \n",
    "        table_matches =  await vector_connector.getSimilarMatches('table', USER_DATABASE, embedded_question, num_table_matches, similarity_threshold)\n",
    "        column_matches =  await vector_connector.getSimilarMatches('column', USER_DATABASE, embedded_question, num_column_matches, similarity_threshold)\n",
    "    else:\n",
    "        table_matches =  vector_connector.getSimilarMatches('table', USER_DATABASE, embedded_question, num_table_matches, similarity_threshold)\n",
    "        column_matches =  vector_connector.getSimilarMatches('column', USER_DATABASE, embedded_question, num_column_matches, similarity_threshold)\n",
    "\n",
    "    AUDIT_TEXT = AUDIT_TEXT +  process_step + \"\\nRetrieved Similar Known Good Queries, Table Schema and Column Schema: \\n\" + '\\nRetrieved Tables: \\n' + str(table_matches) + '\\n\\nRetrieved Columns: \\n' + str(column_matches) + '\\n\\nRetrieved Known Good Queries: \\n' + str(similar_sql)\n",
    "    # If similar table and column schemas found: \n",
    "    if len(table_matches.replace('Schema(values):','').replace(' ','')) > 0 or len(column_matches.replace('Column name(type):','').replace(' ','')) > 0 :\n",
    "\n",
    "        # GENERATE SQL\n",
    "        process_step = \"\\n\\nBuild SQL: \"\n",
    "        generated_sql = SQLBuilder.build_sql(DATA_SOURCE,user_question,table_matches,column_matches,similar_sql)\n",
    "        final_sql=generated_sql\n",
    "        AUDIT_TEXT = AUDIT_TEXT + process_step +  \"\\nGenerated SQL : \" + str(generated_sql)\n",
    "        \n",
    "        if 'unrelated_answer' in generated_sql :\n",
    "            invalid_response=True\n",
    "\n",
    "        # If agent assessment is valid, proceed with checks  \n",
    "        else:\n",
    "            invalid_response=False\n",
    "\n",
    "            if RUN_DEBUGGER: \n",
    "                generated_sql, invalid_response, AUDIT_TEXT = SQLDebugger.start_debugger(DATA_SOURCE, generated_sql, user_question, SQLChecker, table_matches, column_matches, AUDIT_TEXT, similar_sql) \n",
    "                # AUDIT_TEXT = AUDIT_TEXT + '\\n Feedback from Debugger: \\n' + feedback_text\n",
    "\n",
    "            final_sql=generated_sql\n",
    "            AUDIT_TEXT = AUDIT_TEXT + \"\\nFinal SQL after Debugger: \\n\" +str(final_sql)\n",
    "\n",
    "\n",
    "    # No matching table found \n",
    "    else:\n",
    "        invalid_response=True\n",
    "        print('No tables found in Vector ...')\n",
    "        AUDIT_TEXT = AUDIT_TEXT + \"\\nNo tables have been found in the Vector DB. The question cannot be answered with the provide data source!\"\n",
    "\n",
    "print(f'\\n\\n AUDIT_TEXT: \\n {AUDIT_TEXT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: WHich animal was the heaviest?\n",
      "\n",
      "Final Answer:## I'm sorry, but I can't answer your question.\n",
      "\n",
      "According to the data provided, there are no animals in the database. Therefore, I cannot tell you which animal was the heaviest.\n",
      "\n",
      "Is there any other information you can provide that might help me answer your question? For example, do you know what time period the data covers? Or, are there any other animals in the database that you are interested in?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Log Row added'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not invalid_response:\n",
    "    try: \n",
    "        if EXECUTE_FINAL_SQL is True:\n",
    "                final_exec_result_df=src_connector.retrieve_df(final_sql.replace(\"```sql\",\"\").replace(\"```\",\"\").replace(\"EXPLAIN ANALYZE \",\"\"))\n",
    "                print('\\nQuestion: ' + user_question + '\\n')\n",
    "                # print('\\n Final SQL Execution Result: \\n')\n",
    "                # print(final_exec_result_df)\n",
    "                response = final_exec_result_df\n",
    "                _resp=Responder.run(user_question, response)\n",
    "                AUDIT_TEXT = AUDIT_TEXT + \"\\nModel says \" + str(_resp) \n",
    "\n",
    "\n",
    "        else:  # Do not execute final SQL\n",
    "                print(\"Not executing final SQL since EXECUTE_FINAL_SQL variable is False\\n \")\n",
    "                response = \"Please enable the Execution of the final SQL so I can provide an answer\"\n",
    "                _resp=Responder.run(user_question, response)\n",
    "                AUDIT_TEXT = AUDIT_TEXT + \"\\nModel says \" + str(_resp) \n",
    "\n",
    "    except ValueError: \n",
    "          print('')\n",
    "    # except Exception as e: \n",
    "    #     print(f\"An error occured. Aborting... Error Message: {e}\")\n",
    "        \n",
    "else:  # Do not execute final SQL\n",
    "    print(\"Not executing final SQL as it is invalid, please debug!\")\n",
    "    response = \"I am sorry, I could not come up with a valid SQL.\"\n",
    "    _resp=Responder.run(user_question, response)\n",
    "    AUDIT_TEXT = AUDIT_TEXT + \"\\nModel says \" + str(_resp)\n",
    "\n",
    "print(\"Final Answer:\" + str(_resp))\n",
    "bqconnector.make_audit_entry(DATA_SOURCE, USER_DATABASE, \"gemini-1.0-pro\", user_question, final_sql, found_in_vector, \"\", process_step, \"\", AUDIT_TEXT)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Charts for the results (Run only when you have proper results in the above cells)\n",
    "Agent provides two suggestive google charts to display on a UI with element IDs chart_div and chart_div_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charts Suggested : ['Bar Chart', 'Table Chart']\n"
     ]
    }
   ],
   "source": [
    "chart_js=''\n",
    "chart_js = Visualize.generate_charts(user_question,final_sql,response) #sending \n",
    "# print(chart_js[\"chart_div_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script type=\"text/javascript\" src=\"https://www.gstatic.com/charts/loader.js\"></script>\n",
       "<script type=\"text/javascript\">\n",
       "google.charts.load('current', {packages: ['corechart']});\n",
       "google.charts.setOnLoadCallback(drawChart);\n",
       "    function drawChart() {\n",
       "      var data = google.visualization.arrayToDataTable([\n",
       "        ['Breed', 'Kill Weight'],\n",
       "        ['Aberdeen Angus',1.527],\n",
       "        ['Angus-Hereford',3.763],\n",
       "        ['Belgian Blue',4.381],\n",
       "        ['Charolais',3.243],\n",
       "        ['Dairy Shorthorn',1.250],\n",
       "        ['Friesian',1.584],\n",
       "        ['Hereford',1.856],\n",
       "        ['Limousin',3.862],\n",
       "        ['Simmental',1.527],\n",
       "        ['South Devon',3.428]\n",
       "      ]);\n",
       "\n",
       "      var options = {\n",
       "        title: 'Heaviest Animal Breed',\n",
       "        width: 600,\n",
       "        height: 300,\n",
       "        hAxis: {\n",
       "          textStyle: {\n",
       "            fontSize: 12\n",
       "          }\n",
       "        },\n",
       "        vAxis: {\n",
       "          textStyle: {\n",
       "            fontSize: 12\n",
       "          }\n",
       "        },\n",
       "        legend: {\n",
       "          textStyle: {\n",
       "            fontSize: 12\n",
       "          }\n",
       "        },\n",
       "        bar: {\n",
       "          groupWidth: '50%'\n",
       "        }\n",
       "      };\n",
       "\n",
       "      var chart = new google.visualization.BarChart(document.getElementById('chart_div'));\n",
       "\n",
       "      chart.draw(data, options);\n",
       "    }\n",
       "</script>\n",
       "<div id=\"chart_div\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "html_code = f'''\n",
    "<script type=\"text/javascript\" src=\"https://www.gstatic.com/charts/loader.js\"></script>\n",
    "<script type=\"text/javascript\">\n",
    "{chart_js[\"chart_div\"]}\n",
    "</script>\n",
    "<div id=\"chart_div\"></div>\n",
    "'''\n",
    "\n",
    "HTML(html_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script type=\"text/javascript\" src=\"https://www.gstatic.com/charts/loader.js\"></script>\n",
       "<script type=\"text/javascript\">\n",
       "google.charts.load('current', {packages: ['table']});\n",
       "google.charts.setOnLoadCallback(drawTable);\n",
       "\n",
       "function drawTable() {\n",
       "  var data = new google.visualization.DataTable();\n",
       "  data.addColumn('string', 'Animal Subtype');\n",
       "  data.addColumn('number', 'Kill Fat Score');\n",
       "  data.addColumn('number', 'Kill Fat Score Int');\n",
       "  data.addColumn('number', 'Kill Quality Int');\n",
       "  data.addColumn('number', 'Kill Weight');\n",
       "  data.addColumn('string', 'Name');\n",
       "  data.addColumn('string', 'Pedigree');\n",
       "\n",
       "  data.addRows([\n",
       "    ['', null, null, null, null, '', ''],\n",
       "  ]);\n",
       "\n",
       "  var options = {\n",
       "    title: 'Which animal was the heaviest?',\n",
       "    width: 600,\n",
       "    height: 300,\n",
       "    hAxis: {\n",
       "      textStyle: {\n",
       "        fontSize: 12\n",
       "      }\n",
       "    },\n",
       "    vAxis: {\n",
       "      textStyle: {\n",
       "        fontSize: 12\n",
       "      }\n",
       "    },\n",
       "    legend: {\n",
       "      textStyle: {\n",
       "        fontSize: 12\n",
       "      }\n",
       "    }\n",
       "  };\n",
       "\n",
       "  var table = new google.visualization.Table(document.getElementById('chart_div_1'));\n",
       "\n",
       "  table.draw(data, options);\n",
       "}\n",
       "</script>\n",
       "<div id=\"chart_div_1\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_code = f'''\n",
    "<script type=\"text/javascript\" src=\"https://www.gstatic.com/charts/loader.js\"></script>\n",
    "<script type=\"text/javascript\">\n",
    "{chart_js[\"chart_div_1\"]}\n",
    "</script>\n",
    "<div id=\"chart_div_1\"></div>\n",
    "'''\n",
    "\n",
    "HTML(html_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talktodata-V8t31u4d-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
